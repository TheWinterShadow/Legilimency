version: '3.8'

services:
  # vmagent: VictoriaMetrics agent for scraping metrics and remote writing to Grafana Cloud
  # This is the central component that scrapes all exporters and pushes to Grafana Cloud
  vmagent:
    image: victoriametrics/vmagent:v1.103.0
    container_name: vmagent
    restart: unless-stopped
    command:
      - '--promscrape.config=/etc/prometheus/prometheus.yml'
      - '--remoteWrite.url=${GRAFANA_CLOUD_PROMETHEUS_URL}'
      - '--remoteWrite.basicAuth.username=${GRAFANA_CLOUD_USERNAME}'
      - '--remoteWrite.basicAuth.password=${GRAFANA_CLOUD_API_KEY}'
      - '--remoteWrite.tmpDataPath=/vmagent-data'
      - '--remoteWrite.maxDiskUsagePerURL=1GB'
      - '--remoteWrite.queues=4'
      - '--remoteWrite.maxBlockSize=67108864'
      - '--remoteWrite.flushInterval=15s'
      - '--remoteWrite.label=cluster=homelab'
      - '--remoteWrite.label=environment=production'
      - '--remoteWrite.label=source=raspberry-pi'
    volumes:
      - ./configs/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - vmagent-data:/vmagent-data
    ports:
      - "8429:8429"  # Metrics endpoint for vmagent self-monitoring
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8429/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    networks:
      - monitoring
    depends_on:
      yace:
        condition: service_healthy
      stackdriver-exporter:
        condition: service_healthy
      node-exporter:
        condition: service_healthy
      cadvisor:
        condition: service_healthy

  # YACE: Yet Another CloudWatch Exporter
  # Exposes AWS CloudWatch metrics in Prometheus format
  yace:
    image: quay.io/integrations/yet-another-cloudwatch-exporter:v0.60.0
    container_name: yace
    restart: unless-stopped
    command:
      - '--config.file=/etc/yace/config.yml'
      - '--debug=false'
      - '--fargate=true'
    volumes:
      - ./configs/yace-config.yml:/etc/yace/config.yml:ro
    ports:
      - "5000:5000"  # Metrics endpoint
    environment:
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_REGION: ${AWS_REGION}
      AWS_REGIONS_TO_MONITOR: ${AWS_REGIONS_TO_MONITOR}
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:5000/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    networks:
      - monitoring

  # Stackdriver Exporter: GCP Cloud Monitoring exporter
  # Exposes GCP metrics in Prometheus format
  stackdriver-exporter:
    image: prometheuscommunity/stackdriver-exporter:v0.15.0
    container_name: stackdriver-exporter
    restart: unless-stopped
    command:
      - '--google.project-id=${GCP_PROJECT_ID}'
      - '--monitoring.metrics-type-prefixes=compute.googleapis.com,run.googleapis.com,pubsub.googleapis.com,cloudfunctions.googleapis.com'
      - '--monitoring.metrics-interval=60s'
    volumes:
      - ${GCP_KEY_PATH}:/etc/gcp/key.json:ro
    ports:
      - "9255:9255"  # Metrics endpoint
    environment:
      GOOGLE_APPLICATION_CREDENTIALS: /etc/gcp/key.json
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9255/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    networks:
      - monitoring

  # Node Exporter: System metrics for Raspberry Pi
  # Exposes CPU, memory, disk, network metrics
  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: node-exporter
    restart: unless-stopped
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
      - '--collector.netclass.ignored-devices=^(veth.*|docker.*|br-.*)$$'
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    ports:
      - "9100:9100"  # Metrics endpoint
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:9100/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 128M
          cpus: '0.25'
        reservations:
          memory: 64M
          cpus: '0.1'
    networks:
      - monitoring

  # cAdvisor: Container metrics
  # Exposes Docker container CPU, memory, network, filesystem metrics
  cadvisor:
    image: gcr.io/cadvisor/cadvisor:v0.47.2
    container_name: cadvisor
    restart: unless-stopped
    privileged: true
    devices:
      - /dev/kmsg:/dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:ro
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
    ports:
      - "8080:8080"  # Web UI (optional)
      - "8081:8081"  # Metrics endpoint
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:8081/metrics"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: '0.5'
        reservations:
          memory: 128M
          cpus: '0.25'
    networks:
      - monitoring

volumes:
  # Persistent storage for vmagent buffering during network outages
  vmagent-data:
    driver: local

networks:
  monitoring:
    driver: bridge
    name: monitoring-network
